{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd87bb0-1954-441b-afac-6209ce496099",
   "metadata": {},
   "source": [
    "# Process Lecture Notes Markdown to JSON Hierarchy\n",
    "\n",
    "## Convert a Markdown lecture notes file into a hierarchical JSON structure.\n",
    "\n",
    "## Rules implemented:\n",
    "1) Headings starting with '#' define hierarchy levels (# -> 1, ## -> 2, etc.).\n",
    "2) Each section node stores:\n",
    "   - id: hierarchical identifier like \"1\", \"1.2\", \"2.1.3\"\n",
    "   - level: integer heading level (1 for '#', 2 for '##', ...)\n",
    "   - content: raw Markdown content belonging to that section\n",
    "   - title: heading text (extra field; helpful for inspection)\n",
    "   - children: nested subsections\n",
    "3) A line that starts with '#' and ENDS with ':code' is NOT treated as a heading;\n",
    "   it is preserved verbatim in the current section content.\n",
    "4) Headings are ignored within fenced code blocks (``` or ~~~) and display-math blocks ($$ and `\\[\\]` on its own line).\n",
    "5) Any text before the first heading is captured in a synthetic preamble node at level 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c7366-2f10-4c88-8ce1-333ade4cdcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re, os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Union, Iterable, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a70101-9e4e-45c8-a6ae-84397cbde169",
   "metadata": {},
   "source": [
    "## Parse Markdown to JSON Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af9f593-3aad-4501-8fbc-f8399521c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADING_RE = re.compile(r'^(?P<hashes>#{1,})(?P<sp>\\s+)(?P<title>.*)$')\n",
    "\n",
    "def parse_markdown_to_tree(md_text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse Markdown into a hierarchical section tree.\n",
    "\n",
    "    Returns a root dict:\n",
    "    {\n",
    "      \"id\": \"0\",\n",
    "      \"level\": 0,\n",
    "      \"type\": \"section\",\n",
    "      \"title\": \"__ROOT__\",\n",
    "      \"content\": \"<preamble-if-any>\",\n",
    "      \"children\": [ ... section nodes ... ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Root node (level 0) holds optional preamble content and all top-level sections\n",
    "    root = {\n",
    "        \"id\": \"0\",\n",
    "        \"level\": 0,\n",
    "        \"type\": \"section\",\n",
    "        \"title\": \"__ROOT__\",\n",
    "        \"content\": \"\",\n",
    "        \"children\": []\n",
    "    }\n",
    "\n",
    "    # Stack of the current path of nodes; index 0 is the root\n",
    "    node_stack: List[Dict[str, Any]] = [root]\n",
    "\n",
    "    # Counters for hierarchical ids, e.g., [2, 1, 3] -> \"2.1.3\"\n",
    "    counters: List[int] = []\n",
    "\n",
    "    \n",
    "    # Helper: get the current node to append content to (last of stack)\n",
    "    def current_node() -> Dict[str, Any]:\n",
    "        return node_stack[-1]\n",
    "\n",
    "    # Helper: create a new section node and attach it under its parent\n",
    "    def start_section(level: int, title: str) -> Dict[str, Any]:\n",
    "        nonlocal counters\n",
    "\n",
    "        # Ensure counters has at least `level` entries; truncate deeper levels\n",
    "        if len(counters) < level:\n",
    "            counters.extend([0] * (level - len(counters)))\n",
    "        else:\n",
    "            counters = counters[:level]\n",
    "\n",
    "        # Increment the counter for this level\n",
    "        counters[level - 1] += 1\n",
    "\n",
    "        # Hierarchical id like \"1\", \"1.2\", ...\n",
    "        section_id = \".\".join(str(x) for x in counters[:level])\n",
    "\n",
    "        node = {\n",
    "            \"id\": section_id,\n",
    "            \"level\": level,\n",
    "            \"type\": \"section\",\n",
    "            \"title\": title.strip(),\n",
    "            \"content\": \"\",\n",
    "            \"children\": []\n",
    "        }\n",
    "\n",
    "        # Adjust the node stack to this level:\n",
    "        # Ensure parent is level-1; root has level 0\n",
    "        # Pop until stack size == level (parent at index level-1)\n",
    "        while len(node_stack) > level:\n",
    "            node_stack.pop()\n",
    "\n",
    "        # Parent is the node at level-1\n",
    "        parent = node_stack[-1]\n",
    "        parent[\"children\"].append(node)\n",
    "        node_stack.append(node)\n",
    "        return node\n",
    "\n",
    "    lines = md_text.splitlines(keepends=True)\n",
    "\n",
    "    for raw_line in lines:\n",
    "\n",
    "        # remove any line number from the raw_line\n",
    "        cleaned_line = re.sub(r'^\\d+:\\s*', '', raw_line)\n",
    "        \n",
    "        \n",
    "        # Outside of fences: check heading syntax\n",
    "        # If the line starts with '#' and ends with ':code' -> treat as content (special rule)\n",
    "        stripped = cleaned_line.rstrip(\"\\n\")\n",
    "        if stripped.startswith(\"#\") and stripped.endswith(\":code\"):\n",
    "            # Do NOT parse as heading; keep verbatim\n",
    "            #cleaned_cleaned_line = re.sub(r'(:code|:markdown)$', '', cleaned_line)\n",
    "            current_node()[\"content\"] += cleaned_line\n",
    "            continue\n",
    "\n",
    "        m = HEADING_RE.match(stripped)\n",
    "        if m:\n",
    "            hashes = m.group(\"hashes\")\n",
    "            title = m.group(\"title\")\n",
    "            level = len(hashes)\n",
    "\n",
    "            # Create a new section node at this level\n",
    "\n",
    "            #cleaned_title = re.sub(r'(:code|:markdown)$', '', title)\n",
    "            start_section(level, title)\n",
    "            # Heading lines themselves are not part of the section content,\n",
    "            # but you could uncomment the next line to include them if desired:\n",
    "            #cleaned_cleaned_line = re.sub(r'(:code|:markdown)$', '', cleaned_line)\n",
    "            #current_node()[\"content\"] += cleaned_cleaned_line\n",
    "          \n",
    "        else:\n",
    "            # Regular content goes into the current node (root if no heading yet)\n",
    "            #cleaned_cleaned_line = re.sub(r'(:code|:markdown)$', '', cleaned_line)\n",
    "            current_node()[\"content\"] += cleaned_line\n",
    "\n",
    "    # Optionally, if root[\"content\"] is only whitespace, you can trim it\n",
    "    # but we’ll keep as-is to preserve exact input.\n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ccacb0-f30d-4a83-9308-194807eda8b3",
   "metadata": {},
   "source": [
    "## Remove :code and :markdown Suffixes\n",
    "\n",
    "Strip trailing ':code' and ':markdown' suffixes from JSON lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0cdb6-93ef-45b3-9772-a5a60d0f7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches optional whitespace + ':' + (code|markdown) at end of a line\n",
    "SUFFIX_RE = re.compile(r\"\\s*:(?:code|markdown)\\s*$\", re.IGNORECASE)\n",
    "\n",
    "TARGET_TOP_KEYS = {\"title\", \"content\"}\n",
    "TARGET_ELEMENT_KEYS = {\"raw\", \"clean\"}\n",
    "\n",
    "def strip_suffix_from_line(line: str) -> str:\n",
    "    \"\"\"Remove a trailing ':code' or ':markdown' from a single line.\"\"\"\n",
    "    return SUFFIX_RE.sub(\"\", line)\n",
    "\n",
    "def strip_suffix_from_text_block(text: str) -> str:\n",
    "    \"\"\"Process a (possibly multi-line) text block line-by-line.\"\"\"\n",
    "    # Preserve original line endings by splitting on '\\n' and re-joining\n",
    "    lines = text.split(\"\\n\")\n",
    "    return \"\\n\".join(strip_suffix_from_line(ln) for ln in lines)\n",
    "\n",
    "def process_content_elements(elems: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Clean the 'raw' and 'clean' fields within content_elements.\"\"\"\n",
    "    for el in elems:\n",
    "        if not isinstance(el, dict):\n",
    "            continue\n",
    "        for k in list(el.keys()):\n",
    "            if k in TARGET_ELEMENT_KEYS and isinstance(el[k], str):\n",
    "                el[k] = strip_suffix_from_text_block(el[k])\n",
    "    return elems\n",
    "\n",
    "def process_node(node: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Recursively traverse a section/node dict and clean targeted string fields.\n",
    "    Expects a structure similar to the uploaded lecture notes JSON.\n",
    "    \"\"\"\n",
    "    # Clean top-level targeted keys if present\n",
    "    for k in list(node.keys()):\n",
    "        v = node[k]\n",
    "        if k in TARGET_TOP_KEYS and isinstance(v, str):\n",
    "            node[k] = strip_suffix_from_text_block(v)\n",
    "\n",
    "    # Clean content_elements array if present\n",
    "    if \"content_elements\" in node and isinstance(node[\"content_elements\"], list):\n",
    "        node[\"content_elements\"] = process_content_elements(node[\"content_elements\"])\n",
    "\n",
    "    # Recurse into children\n",
    "    if \"children\" in node and isinstance(node[\"children\"], list):\n",
    "        for child in node[\"children\"]:\n",
    "            if isinstance(child, dict):\n",
    "                process_node(child)\n",
    "\n",
    "    return node\n",
    "\n",
    "def process_json(obj: Union[Dict[str, Any], List[Any]]) -> Union[Dict[str, Any], List[Any]]:\n",
    "    \"\"\"\n",
    "    Entry point for cleaning; supports top-level dict or list of dicts.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return process_node(obj)\n",
    "    elif isinstance(obj, list):\n",
    "        return [process_node(x) if isinstance(x, dict) else x for x in obj]\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79519c70-d8ec-490b-a693-71334310bd37",
   "metadata": {},
   "source": [
    "## Break Down to Individual Elements\n",
    "\n",
    "Parse a lecture-notes-like JSON file and, for every object with a 'content' key,\n",
    "add a new sibling key 'content_elements' that lists the identified elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49194019-1ea1-4ed7-859b-7ddbbe80a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parse a lecture-notes-like JSON file and, for every object with a 'content' key,\n",
    "add a new sibling key 'content_elements' that lists the identified elements.\n",
    "\n",
    "Element types detected (line-granularity, with basic multi-line grouping):\n",
    "- 'code'      : lines marked with ':code' or between triple-backtick fences\n",
    "- 'markdown'  : lines marked with ':markdown'\n",
    "- 'math'      : LaTeX-style math ($...$, $$...$$, \\(...\\), \\[...\\], \\begin{equation}...\\end{equation})\n",
    "- 'image'     : Markdown images ![alt](url) or <img ... src=\"...\">\n",
    "- 'video'     : <iframe ...> embeds or URLs from video domains (YouTube, Vimeo, etc.)\n",
    "- 'link'      : bare URLs that are not images/videos\n",
    "- 'html'      : other HTML tags (non-img/non-iframe) on the line\n",
    "- 'text'      : anything else after marker stripping\n",
    "- 'other'     : fallback\n",
    "\n",
    "Each element preserves:\n",
    "- 'raw'    : the original line or grouped block (verbatim)\n",
    "- 'clean'  : a cleaned version (markers removed; trimmed)\n",
    "- 'meta'   : metadata such as line numbers, detected markers, URLs, language hints\n",
    "\"\"\"\n",
    "\n",
    "# ---------- Regexes for detection ----------\n",
    "\n",
    "# Markdown image: ![alt](url)\n",
    "RE_MD_IMAGE = re.compile(r'!\\[[^\\]]*\\]\\((?P<url>[^)]+)\\)')\n",
    "\n",
    "# HTML <img ... src=\"...\">\n",
    "RE_HTML_IMAGE = re.compile(r'<img\\s+[^>]*src=[\"\\'](?P<url>[^\"\\']+)[\"\\'][^>]*>', re.IGNORECASE)\n",
    "\n",
    "# HTML <iframe ... src=\"...\">\n",
    "RE_IFRAME = re.compile(r'<iframe\\s+[^>]*src=[\"\\'](?P<url>[^\"\\']+)[\"\\'][^>]*>', re.IGNORECASE)\n",
    "\n",
    "# Bare URL (very permissive)\n",
    "RE_URL = re.compile(\n",
    "    r'(?P<url>(?:https?://|www\\.)[^\\s)<>\\]]+)', re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Code fence ```\n",
    "RE_FENCE_OPEN = re.compile(r'^\\s*```(?P<lang>[A-Za-z0-9_\\-+]*)\\s*$')\n",
    "RE_FENCE_CLOSE = re.compile(r'^\\s*```\\s*$')\n",
    "\n",
    "# LaTeX math (inline and display)\n",
    "RE_INLINE_MATH = re.compile(r'(?<!\\\\)\\$(?P<expr>[^$]+?)(?<!\\\\)\\$')\n",
    "RE_BLOCK_MATH_INLINE = re.compile(r'(?<!\\\\)\\$\\$(?P<expr>.+?)(?<!\\\\)\\$\\$')\n",
    "RE_BEGIN_ENV = re.compile(r'\\\\begin\\{(?P<env>equation\\*?|align\\*?|gather\\*?|multline\\*?)\\}')\n",
    "RE_END_ENV = re.compile(r'\\\\end\\{(?P<env>equation\\*?|align\\*?|gather\\*?|multline\\*?)\\}')\n",
    "RE_PAREN_MATH = re.compile(r'\\\\\\((?P<expr>.+?)\\\\\\)')\n",
    "RE_BRACKET_MATH = re.compile(r'\\\\\\[(?P<expr>.+?)\\\\\\]')\n",
    "\n",
    "# Generic HTML tag (for html detection; exclude img/iframe which are handled separately)\n",
    "RE_HTML_GENERIC = re.compile(r'<([a-zA-Z][a-zA-Z0-9]*)\\b[^>]*>.*</\\1\\s*>')\n",
    "\n",
    "# ':code' / ':markdown' markers (suffixes in this dataset)\n",
    "RE_MARKER_SUFFIX = re.compile(r'(?P<core>.*?)(?::(?P<marker>code|markdown))\\s*$')\n",
    "\n",
    "# Video domains and file extensions\n",
    "VIDEO_DOMAINS = (\n",
    "    'youtube.com', 'youtu.be', 'vimeo.com', 'dailymotion.com', 'video.google.com'\n",
    ")\n",
    "VIDEO_EXTS = ('.mp4', '.mov', '.webm', '.mkv', '.avi', '.m4v')\n",
    "\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "\n",
    "def _has_video_signature(url: str) -> bool:\n",
    "    url_low = url.lower()\n",
    "    if any(dom in url_low for dom in VIDEO_DOMAINS):\n",
    "        return True\n",
    "    if any(url_low.endswith(ext) for ext in VIDEO_EXTS):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def _strip_marker_suffix(line: str) -> Tuple[str, Optional[str]]:\n",
    "    \"\"\"Remove a trailing ':code' or ':markdown' marker; return (clean, marker|None).\"\"\"\n",
    "    m = RE_MARKER_SUFFIX.match(line.rstrip('\\n'))\n",
    "    if m:\n",
    "        return m.group('core'), m.group('marker')\n",
    "    return line.rstrip('\\n'), None\n",
    "\n",
    "\n",
    "def _first_url(line: str) -> Optional[str]:\n",
    "    m = RE_URL.search(line)\n",
    "    if m:\n",
    "        return m.group('url')\n",
    "    return None\n",
    "\n",
    "\n",
    "def _is_html_other_than_img_iframe(line: str) -> bool:\n",
    "    # Detect presence of other HTML tags (heuristic)\n",
    "    if RE_IFRAME.search(line) or RE_HTML_IMAGE.search(line):\n",
    "        return False\n",
    "    return bool(RE_HTML_GENERIC.search(line))\n",
    "\n",
    "\n",
    "# ---------- Element construction ----------\n",
    "\n",
    "def _make_element(\n",
    "    etype: str,\n",
    "    raw: str,\n",
    "    clean: str,\n",
    "    line_start: int,\n",
    "    line_end: Optional[int] = None,\n",
    "    url: Optional[str] = None,\n",
    "    marker: Optional[str] = None,\n",
    "    lang: Optional[str] = None\n",
    ") -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"type\": etype,\n",
    "        \"raw\": raw,\n",
    "        \"clean\": clean.strip(),\n",
    "        \"meta\": {\n",
    "            \"line_start\": line_start,\n",
    "            \"line_end\": line_end if line_end is not None else line_start,\n",
    "            \"marker\": marker,\n",
    "            \"url\": url,\n",
    "            \"lang\": lang,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------- Core parsing (per content string) ----------\n",
    "\n",
    "def parse_content_to_elements(content: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert a raw content string into a list of element dicts,\n",
    "    applying line-based splitting and multi-line grouping for code/math blocks.\n",
    "    \"\"\"\n",
    "    if not content:\n",
    "        return []\n",
    "\n",
    "    lines = content.splitlines()\n",
    "    elements: List[Dict[str, Any]] = []\n",
    "\n",
    "    in_code_fence = False\n",
    "    code_fence_lang: Optional[str] = None\n",
    "    code_buffer: List[str] = []\n",
    "    code_start_line: Optional[int] = None\n",
    "\n",
    "    in_math_env = False\n",
    "    math_env_buffer: List[str] = []\n",
    "    math_start_line: Optional[int] = None\n",
    "\n",
    "    def flush_code_block(end_line_idx: int) -> None:\n",
    "        nonlocal code_buffer, code_fence_lang, code_start_line\n",
    "        if code_buffer:\n",
    "            raw = \"\\n\".join(code_buffer)\n",
    "            clean = raw\n",
    "            elements.append(\n",
    "                _make_element(\n",
    "                    etype=\"code\",\n",
    "                    raw=raw,\n",
    "                    clean=clean,\n",
    "                    line_start=code_start_line if code_start_line is not None else end_line_idx,\n",
    "                    line_end=end_line_idx,\n",
    "                    lang=code_fence_lang,\n",
    "                )\n",
    "            )\n",
    "            code_buffer = []\n",
    "        code_fence_lang = None\n",
    "        code_start_line = None\n",
    "\n",
    "    def flush_math_block(end_line_idx: int) -> None:\n",
    "        nonlocal math_env_buffer, math_start_line\n",
    "        if math_env_buffer:\n",
    "            raw = \"\\n\".join(math_env_buffer)\n",
    "            clean = raw\n",
    "            elements.append(\n",
    "                _make_element(\n",
    "                    etype=\"math\",\n",
    "                    raw=raw,\n",
    "                    clean=clean,\n",
    "                    line_start=math_start_line if math_start_line is not None else end_line_idx,\n",
    "                    line_end=end_line_idx,\n",
    "                )\n",
    "            )\n",
    "            math_env_buffer = []\n",
    "        math_start_line = None\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        line_num = i + 1  # 1-based\n",
    "\n",
    "        # Code fence handling\n",
    "        if not in_code_fence:\n",
    "            m_open = RE_FENCE_OPEN.match(line)\n",
    "            if m_open:\n",
    "                in_code_fence = True\n",
    "                code_fence_lang = m_open.group('lang') or None\n",
    "                code_buffer = [line]  # include fence line in raw\n",
    "                code_start_line = line_num\n",
    "                i += 1\n",
    "                continue\n",
    "        else:\n",
    "            code_buffer.append(line)\n",
    "            if RE_FENCE_CLOSE.match(line):\n",
    "                in_code_fence = False\n",
    "                flush_code_block(line_num)\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Math environment handling (LaTeX \\begin{equation} ... \\end{equation})\n",
    "        if not in_math_env:\n",
    "            if RE_BEGIN_ENV.search(line):\n",
    "                in_math_env = True\n",
    "                math_env_buffer = [line]\n",
    "                math_start_line = line_num\n",
    "                i += 1\n",
    "                continue\n",
    "        else:\n",
    "            math_env_buffer.append(line)\n",
    "            if RE_END_ENV.search(line):\n",
    "                in_math_env = False\n",
    "                flush_math_block(line_num)\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Strip ':code' / ':markdown' markers (dataset-specific)\n",
    "        core, marker = _strip_marker_suffix(line)\n",
    "        core_stripped = core.strip()\n",
    "\n",
    "        # Detect image (Markdown or HTML)\n",
    "        img_md = RE_MD_IMAGE.search(core_stripped)\n",
    "        img_html = RE_HTML_IMAGE.search(core_stripped)\n",
    "        if img_md:\n",
    "            url = img_md.group('url')\n",
    "            elements.append(_make_element(\"image\", raw=line, clean=core_stripped, line_start=line_num, url=url, marker=marker))\n",
    "            i += 1\n",
    "            continue\n",
    "        if img_html:\n",
    "            url = img_html.group('url')\n",
    "            elements.append(_make_element(\"image\", raw=line, clean=core_stripped, line_start=line_num, url=url, marker=marker))\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Detect video (iframe or video-like URL)\n",
    "        iframe = RE_IFRAME.search(core_stripped)\n",
    "        if iframe:\n",
    "            url = iframe.group('url')\n",
    "            elements.append(_make_element(\"video\", raw=line, clean=core_stripped, line_start=line_num, url=url, marker=marker))\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        url = _first_url(core_stripped)\n",
    "        if url and _has_video_signature(url):\n",
    "            elements.append(_make_element(\"video\", raw=line, clean=core_stripped, line_start=line_num, url=url, marker=marker))\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Detect inline/display math on the line\n",
    "        if RE_BLOCK_MATH_INLINE.search(core_stripped) or RE_INLINE_MATH.search(core_stripped) \\\n",
    "           or RE_PAREN_MATH.search(core_stripped) or RE_BRACKET_MATH.search(core_stripped):\n",
    "            elements.append(_make_element(\"math\", raw=line, clean=core_stripped, line_start=line_num, marker=marker))\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Detect code by ':code' marker (common in provided context)\n",
    "        if marker == 'code':\n",
    "            elements.append(_make_element(\"code\", raw=line, clean=core_stripped, line_start=line_num, marker=marker))\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Detect generic HTML (non-img/non-iframe)\n",
    "        if _is_html_other_than_img_iframe(core_stripped):\n",
    "            elements.append(_make_element(\"html\", raw=line, clean=core_stripped, line_start=line_num, marker=marker))\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Detect link (non-video)\n",
    "        if url:\n",
    "            elements.append(_make_element(\"link\", raw=line, clean=core_stripped, line_start=line_num, url=url, marker=marker))\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Treat explicit ':markdown' marker as markdown text\n",
    "        if marker == 'markdown':\n",
    "            elements.append(_make_element(\"markdown\", raw=line, clean=core_stripped, line_start=line_num, marker=marker))\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Empty line → represent as empty text element (helps preserve structure)\n",
    "        if core_stripped == \"\":\n",
    "            elements.append(_make_element(\"text\", raw=line, clean=\"\", line_start=line_num, marker=marker))\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Default: plain text\n",
    "        elements.append(_make_element(\"text\", raw=line, clean=core_stripped, line_start=line_num, marker=marker))\n",
    "        i += 1\n",
    "\n",
    "    # Flush any unclosed blocks (defensive)\n",
    "    if in_code_fence:\n",
    "        flush_code_block(len(lines))\n",
    "    if in_math_env:\n",
    "        flush_math_block(len(lines))\n",
    "\n",
    "    return elements\n",
    "\n",
    "\n",
    "# ---------- Tree traversal (mutates in-place) ----------\n",
    "\n",
    "def add_elements_recursively(node: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    For a node (dict) with 'content', add 'content_elements' using the parser above.\n",
    "    Recurse into 'children' if present.\n",
    "    \"\"\"\n",
    "    if isinstance(node, dict):\n",
    "        if 'content' in node and isinstance(node['content'], str):\n",
    "            node['content_elements'] = parse_content_to_elements(node['content'])\n",
    "\n",
    "        # Recurse into children (if any)\n",
    "        if 'children' in node and isinstance(node['children'], list):\n",
    "            for child in node['children']:\n",
    "                add_elements_recursively(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ca50f2-3b97-487d-88ba-e7fd7a85684d",
   "metadata": {},
   "source": [
    "## Run Pipeline on Lecture Notes\n",
    "### From a Markdown Lecture Notes to Hierarchical JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e101787b-f41a-4d9a-92d6-fd8b12188268",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_md_path = Path(\"./data/lecture_notes_8.md\")\n",
    "output_json_path = Path(\"./data/lecture_notes_8.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ad4f8-146e-4c6b-982b-93d1cefe4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_text = input_md_path.read_text(encoding=\"utf-8\", errors=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a6c95-36bb-4008-b857-58d681d03114",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_tree = parse_markdown_to_tree(md_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a337a-2dfc-4ca6-ae1b-fcf78250f027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c37a7-6bd4-4d40-bc84-44b2d878c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_tree_elements_cleaned = process_json(json_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08250679-17a9-4119-a926-1853a6a48daa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_tree_elements_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9dddb7-270b-491f-b6c3-b8496b3c476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_elements_recursively(json_tree_elements_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34a05d-87d6-4f14-919e-b1ddbb48b270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_tree_elements_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f12ff-9901-4bac-b1a8-95d3c37101cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with output_json_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_tree_elements_cleaned, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd45a2-bd9d-4edc-88e4-4cbe65966582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drtutor",
   "language": "python",
   "name": "drtutor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
